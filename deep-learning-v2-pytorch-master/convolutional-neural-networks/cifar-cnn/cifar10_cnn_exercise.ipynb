{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "---\n",
    "In this notebook, we train a **CNN** to classify images from the CIFAR-10 database.\n",
    "\n",
    "The images in this database are small color images that fall into one of ten classes; some example images are pictured below.\n",
    "\n",
    "<img src='notebook_ims/cifar_data.png' width=70% height=70% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for [CUDA](http://pytorch.org/docs/stable/cuda.html)\n",
    "\n",
    "Since these are larger (32x32x3) images, it may prove useful to speed up your training time by using a GPU. CUDA is a parallel computing platform and CUDA Tensors are the same as typical Tensors, only they utilize GPU's for computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.  Training on CPU ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load the [Data](http://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "\n",
    "Downloading may take a minute. We load in the training and test data, split the training data into a training and validation set, then create DataLoaders for each of these sets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170499072it [01:30, 1890412.78it/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "\n",
    "batch_size = 20\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "\n",
    "# convert data to a normalized torch.FloatTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.CIFAR10('data', train=True,\n",
    "                              download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10('data', train=False,\n",
    "                             download=True, transform=transform)\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "    sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "\n",
    "# specify the image classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a Batch of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# helper function to un-normalize and display an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of columns must be a positive integer, not 10.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/ujones/Dropbox/Data Science/Python Project Learning/Udacity/Deep Learning/Course/deep-learning-v2-pytorch-master/convolutional-neural-networks/cifar-cnn/cifar10_cnn_exercise.ipynb Cell 8'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ujones/Dropbox/Data%20Science/Python%20Project%20Learning/Udacity/Deep%20Learning/Course/deep-learning-v2-pytorch-master/convolutional-neural-networks/cifar-cnn/cifar10_cnn_exercise.ipynb#ch0000007?line=7'>8</a>\u001b[0m \u001b[39m# display 20 images\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ujones/Dropbox/Data%20Science/Python%20Project%20Learning/Udacity/Deep%20Learning/Course/deep-learning-v2-pytorch-master/convolutional-neural-networks/cifar-cnn/cifar10_cnn_exercise.ipynb#ch0000007?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39marange(\u001b[39m20\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ujones/Dropbox/Data%20Science/Python%20Project%20Learning/Udacity/Deep%20Learning/Course/deep-learning-v2-pytorch-master/convolutional-neural-networks/cifar-cnn/cifar10_cnn_exercise.ipynb#ch0000007?line=9'>10</a>\u001b[0m     ax \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39;49madd_subplot(\u001b[39m2\u001b[39;49m, \u001b[39m20\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m, idx\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m, xticks\u001b[39m=\u001b[39;49m[], yticks\u001b[39m=\u001b[39;49m[])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ujones/Dropbox/Data%20Science/Python%20Project%20Learning/Udacity/Deep%20Learning/Course/deep-learning-v2-pytorch-master/convolutional-neural-networks/cifar-cnn/cifar10_cnn_exercise.ipynb#ch0000007?line=10'>11</a>\u001b[0m     imshow(images[idx])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ujones/Dropbox/Data%20Science/Python%20Project%20Learning/Udacity/Deep%20Learning/Course/deep-learning-v2-pytorch-master/convolutional-neural-networks/cifar-cnn/cifar10_cnn_exercise.ipynb#ch0000007?line=11'>12</a>\u001b[0m     ax\u001b[39m.\u001b[39mset_title(classes[labels[idx]])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/figure.py:772\u001b[0m, in \u001b[0;36mFigureBase.add_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/figure.py?line=768'>769</a>\u001b[0m         args \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mint\u001b[39m, \u001b[39mstr\u001b[39m(args[\u001b[39m0\u001b[39m])))\n\u001b[1;32m    <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/figure.py?line=769'>770</a>\u001b[0m     projection_class, pkw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_projection_requirements(\n\u001b[1;32m    <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/figure.py?line=770'>771</a>\u001b[0m         \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/figure.py?line=771'>772</a>\u001b[0m     ax \u001b[39m=\u001b[39m subplot_class_factory(projection_class)(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpkw)\n\u001b[1;32m    <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/figure.py?line=772'>773</a>\u001b[0m     key \u001b[39m=\u001b[39m (projection_class, pkw)\n\u001b[1;32m    <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/figure.py?line=773'>774</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_axes_internal(ax, key)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/axes/_subplots.py:36\u001b[0m, in \u001b[0;36mSubplotBase.__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/axes/_subplots.py?line=33'>34</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_axes_class\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, fig, [\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/axes/_subplots.py?line=34'>35</a>\u001b[0m \u001b[39m# This will also update the axes position.\u001b[39;00m\n\u001b[0;32m---> <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/axes/_subplots.py?line=35'>36</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_subplotspec(SubplotSpec\u001b[39m.\u001b[39;49m_from_subplot_args(fig, args))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py:597\u001b[0m, in \u001b[0;36mSubplotSpec._from_subplot_args\u001b[0;34m(figure, args)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=592'>593</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=593'>594</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msubplot() takes 1 or 3 positional arguments but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=594'>595</a>\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(args)\u001b[39m}\u001b[39;00m\u001b[39m were given\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=596'>597</a>\u001b[0m gs \u001b[39m=\u001b[39m GridSpec\u001b[39m.\u001b[39;49m_check_gridspec_exists(figure, rows, cols)\n\u001b[1;32m    <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=597'>598</a>\u001b[0m \u001b[39mif\u001b[39;00m gs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=598'>599</a>\u001b[0m     gs \u001b[39m=\u001b[39m GridSpec(rows, cols, figure\u001b[39m=\u001b[39mfigure)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py:225\u001b[0m, in \u001b[0;36mGridSpecBase._check_gridspec_exists\u001b[0;34m(figure, nrows, ncols)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=222'>223</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m gs\n\u001b[1;32m    <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=223'>224</a>\u001b[0m \u001b[39m# else gridspec not found:\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=224'>225</a>\u001b[0m \u001b[39mreturn\u001b[39;00m GridSpec(nrows, ncols, figure\u001b[39m=\u001b[39;49mfigure)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py:385\u001b[0m, in \u001b[0;36mGridSpec.__init__\u001b[0;34m(self, nrows, ncols, figure, left, bottom, right, top, wspace, hspace, width_ratios, height_ratios)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=381'>382</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhspace \u001b[39m=\u001b[39m hspace\n\u001b[1;32m    <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=382'>383</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure \u001b[39m=\u001b[39m figure\n\u001b[0;32m--> <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=384'>385</a>\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(nrows, ncols,\n\u001b[1;32m    <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=385'>386</a>\u001b[0m                  width_ratios\u001b[39m=\u001b[39;49mwidth_ratios,\n\u001b[1;32m    <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=386'>387</a>\u001b[0m                  height_ratios\u001b[39m=\u001b[39;49mheight_ratios)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py:52\u001b[0m, in \u001b[0;36mGridSpecBase.__init__\u001b[0;34m(self, nrows, ncols, height_ratios, width_ratios)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=48'>49</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=49'>50</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of rows must be a positive integer, not \u001b[39m\u001b[39m{\u001b[39;00mnrows\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=50'>51</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(ncols, Integral) \u001b[39mor\u001b[39;00m ncols \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=51'>52</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=52'>53</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of columns must be a positive integer, not \u001b[39m\u001b[39m{\u001b[39;00mncols\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=53'>54</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nrows, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ncols \u001b[39m=\u001b[39m nrows, ncols\n\u001b[1;32m     <a href='file:///~/.pyenv/versions/3.8.5/envs/machine_learning/lib/python3.8/site-packages/matplotlib/gridspec.py?line=54'>55</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_height_ratios(height_ratios)\n",
      "\u001b[0;31mValueError\u001b[0m: Number of columns must be a positive integer, not 10.0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy() # convert images to numpy for display\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "# display 20 images\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View an Image in More Detail\n",
    "\n",
    "Here, we look at the normalized red, green, and blue (RGB) color channels as three separate, grayscale intensity images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rgb_img = np.squeeze(images[3])\n",
    "channels = ['red channel', 'green channel', 'blue channel']\n",
    "\n",
    "fig = plt.figure(figsize = (36, 36)) \n",
    "for idx in np.arange(rgb_img.shape[0]):\n",
    "    ax = fig.add_subplot(1, 3, idx + 1)\n",
    "    img = rgb_img[idx]\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(channels[idx])\n",
    "    width, height = img.shape\n",
    "    thresh = img.max()/2.5\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
    "            ax.annotate(str(val), xy=(y,x),\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center', size=8,\n",
    "                    color='white' if img[x][y]<thresh else 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define the Network [Architecture](http://pytorch.org/docs/stable/nn.html)\n",
    "\n",
    "This time, you'll define a CNN architecture. Instead of an MLP, which used linear, fully-connected layers, you'll use the following:\n",
    "* [Convolutional layers](https://pytorch.org/docs/stable/nn.html#conv2d), which can be thought of as stack of filtered images.\n",
    "* [Maxpooling layers](https://pytorch.org/docs/stable/nn.html#maxpool2d), which reduce the x-y size of an input, keeping only the most _active_ pixels from the previous layer.\n",
    "* The usual Linear + Dropout layers to avoid overfitting and produce a 10-dim output.\n",
    "\n",
    "A network with 2 convolutional layers is shown in the image below and in the code, and you've been given starter code with one convolutional and one maxpooling layer.\n",
    "\n",
    "<img src='notebook_ims/2_layer_conv.png' height=50% width=50% />\n",
    "\n",
    "#### TODO: Define a model with multiple convolutional layers, and define the feedforward network behavior.\n",
    "\n",
    "The more convolutional layers you include, the more complex patterns in color and shape a model can detect. It's suggested that your final model include 2 or 3 convolutional layers as well as linear layers + dropout in between to avoid overfitting. \n",
    "\n",
    "It's good practice to look at existing research and implementations of related models as a starting point for defining your own models. You may find it useful to look at [this PyTorch classification example](https://github.com/pytorch/tutorials/blob/master/beginner_source/blitz/cifar10_tutorial.py) or [this, more complex Keras example](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py) to help decide on a final structure.\n",
    "\n",
    "#### Output volume for a convolutional layer\n",
    "\n",
    "To compute the output size of a given convolutional layer we can perform the following calculation (taken from [Stanford's cs231n course](http://cs231n.github.io/convolutional-networks/#layers)):\n",
    "> We can compute the spatial size of the output volume as a function of the input volume size (W), the kernel/filter size (F), the stride with which they are applied (S), and the amount of zero padding used (P) on the border. The correct formula for calculating how many neurons define the output_W is given by `(W−F+2P)/S+1`. \n",
    "\n",
    "For example for a 7x7 input and a 3x3 filter with stride 1 and pad 0 we would get a 5x5 output. With stride 2 we would get a 3x3 output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layer\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        return x\n",
    "\n",
    "# create a complete CNN\n",
    "model = Net()\n",
    "print(model)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify [Loss Function](http://pytorch.org/docs/stable/nn.html#loss-functions) and [Optimizer](http://pytorch.org/docs/stable/optim.html)\n",
    "\n",
    "Decide on a loss and optimization function that is best suited for this classification task. The linked code examples from above, may be a good starting point; [this PyTorch classification example](https://github.com/pytorch/tutorials/blob/master/beginner_source/blitz/cifar10_tutorial.py) or [this, more complex Keras example](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py). Pay close attention to the value for **learning rate** as this value determines how your model converges to a small error.\n",
    "\n",
    "#### TODO: Define the loss and optimizer and see how these choices change the loss over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# specify loss function\n",
    "criterion = None\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train the Network\n",
    "\n",
    "Remember to look at how the training and validation loss decreases over time; if the validation loss ever increases it indicates possible overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 8 # you may increase this number to train a final model\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load the Model with the Lowest Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_cifar.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test the Trained Network\n",
    "\n",
    "Test your trained model on previously unseen data! A \"good\" result will be a CNN that gets around 70% (or more, try your best!) accuracy on these test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "for data, target in test_loader:\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What are your model's weaknesses and how might they be improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: (double-click to edit and add an answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Sample Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtain one batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "images.numpy()\n",
    "\n",
    "# move model inputs to cuda, if GPU available\n",
    "if train_on_gpu:\n",
    "    images = images.cuda()\n",
    "\n",
    "# get sample outputs\n",
    "output = model(images)\n",
    "# convert output probabilities to predicted class\n",
    "_, preds_tensor = torch.max(output, 1)\n",
    "preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
    "\n",
    "if train_on_gpu:\n",
    "    images = images.cpu()\n",
    "\n",
    "# plot the images in the batch, along with predicted and true labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx] if not train_on_gpu else images[idx].cpu())\n",
    "    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n",
    "                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
